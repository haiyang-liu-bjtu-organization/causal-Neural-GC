{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cLSTM Lorenz-96 Demo\n",
    "- In this notebook, we train a cLSTM model on data simulated from a Lorenz-96 system"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'/root/autodl-tmp/Neural-GC-master'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "# 显示当前jupyter启动在哪\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T16:32:41.028853Z",
     "start_time": "2024-11-21T16:32:41.018072Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T16:32:42.950976Z",
     "start_time": "2024-11-21T16:32:41.043052Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from models.clstm import cLSTM, train_model_ista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T16:32:43.125596Z",
     "start_time": "2024-11-21T16:32:42.952657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os\n",
    "# from datetime import datetime\n",
    "# import logging\n",
    "# \n",
    "# # 获取当前时间作为文件名的一部分\n",
    "# current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "# log_filename = f\"log_{current_time}.txt\"\n",
    "# \n",
    "# # 确保日志文件夹存在\n",
    "# log_dir = \"logs\"\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.makedirs(log_dir)\n",
    "# \n",
    "# log_path = os.path.join(log_dir, log_filename)\n",
    "# \n",
    "# \n",
    "# # 创建一个同时写入控制台和文件的类\n",
    "# class Logger(object):\n",
    "#     def __init__(self, filename=\"Default.log\"):\n",
    "#         self.terminal = sys.stdout\n",
    "#         self.log = open(filename, \"w\")\n",
    "# \n",
    "#     def write(self, message):\n",
    "#         self.terminal.write(message)\n",
    "#         self.log.write(message)\n",
    "#         self.flush()  # 确保实时写入\n",
    "# \n",
    "#     def flush(self):\n",
    "#         self.terminal.flush()\n",
    "#         self.log.flush()\n",
    "# \n",
    "#     def __del__(self):\n",
    "#         self.log.close()\n",
    "# \n",
    "# \n",
    "# # 重定向 sys.stdout 到 Logger 实例\n",
    "# sys.stdout = Logger(log_path)\n",
    "# \n",
    "# # 示例打印\n",
    "# print(\"This is a test log message.\")\n",
    "# sys.stdout = sys.__stdout__  # 恢复到原始的 sys.stdout\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T16:32:43.129749Z",
     "start_time": "2024-11-21T16:32:43.126665Z"
    }
   },
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T16:32:50.065410Z",
     "start_time": "2024-11-21T16:32:43.130782Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前处理文件是：datasets/lorenz/F10/time1000/lorenz-169-F10-1000.npz\n",
      "Current parameters:\n",
      "CONTEXT = 10,  LAMBDA_RIDGE = 0.01\n",
      "LEARNING_RATE = 0.001, MAX_ITERATIONS = 20000, CHECK_EVERY = 50\n",
      "当前 LAMBDA = 0.1000\n",
      "----------Iter = 50----------\n",
      "Loss = 20.602057\n",
      "Variable usage = 100.00%\n",
      "----------Iter = 100----------\n",
      "Loss = 14.818715\n",
      "Variable usage = 100.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_6818/1772812589.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     48\u001B[0m                         \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mLEARNING_RATE\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m                         \u001B[0mmax_iter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mMAX_ITERATIONS\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m                         \u001B[0mcheck_every\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mCHECK_EVERY\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m                     )\n\u001B[1;32m     52\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/autodl-tmp/Neural-GC-master/models/clstm.py\u001B[0m in \u001B[0;36mtrain_model_ista\u001B[0;34m(clstm, X, context, lr, max_iter, lam, lam_ridge, lookback, check_every, verbose)\u001B[0m\n\u001B[1;32m    481\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    482\u001B[0m         \u001B[0;31m# Calculate loss for next iteration.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 483\u001B[0;31m         \u001B[0mpred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mclstm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnetworks\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    484\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mloss_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpred\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    485\u001B[0m         ridge = sum([ridge_regularize(net, lam_ridge)\n",
      "\u001B[0;32m~/autodl-tmp/Neural-GC-master/models/clstm.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    481\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    482\u001B[0m         \u001B[0;31m# Calculate loss for next iteration.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 483\u001B[0;31m         \u001B[0mpred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mclstm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnetworks\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    484\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mloss_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpred\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mY\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m:\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mp\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    485\u001B[0m         ridge = sum([ridge_regularize(net, lam_ridge)\n",
      "\u001B[0;32m~/miniconda3/envs/NGC37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/autodl-tmp/Neural-GC-master/models/clstm.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, X, hidden)\u001B[0m\n\u001B[1;32m     39\u001B[0m         \u001B[0;31m# Calculate predictions using output layer.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m         \u001B[0mX\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     42\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mhidden\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/NGC37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1100\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1101\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1102\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1103\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1104\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/NGC37/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 301\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_conv_forward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/envs/NGC37/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001B[0m in \u001B[0;36m_conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    296\u001B[0m                             _single(0), self.dilation, self.groups)\n\u001B[1;32m    297\u001B[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001B[0;32m--> 298\u001B[0;31m                         self.padding, self.dilation, self.groups)\n\u001B[0m\u001B[1;32m    299\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    300\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 指定根文件夹路径\n",
    "root_path = 'datasets/lorenz'\n",
    "# Define parameters at the beginning of the file\n",
    "CONTEXT = 10\n",
    "# LAMBDA = 5.0\n",
    "LAMBDA_RIDGE = 1e-2\n",
    "LEARNING_RATE = 1e-3\n",
    "MAX_ITERATIONS = 20000\n",
    "CHECK_EVERY = 50\n",
    "# 定义固定的 lambda 值\n",
    "LAMBDA_RANGE = [0.1, 0.3, 0.7, 1.0, 2.0, 3.5, 5.0, 10.0, 15.0, 20.0]\n",
    "\n",
    "# 遍历文件夹结构\n",
    "for folder1 in os.listdir(root_path):\n",
    "    folder1_path = root_path + '/' + folder1\n",
    "    for folder2 in os.listdir(folder1_path):\n",
    "        folder2_path = folder1_path + '/' + folder2\n",
    "        for file in os.listdir(folder2_path):\n",
    "            if file.endswith('.npz'):\n",
    "                file_path = folder2_path + '/' + file\n",
    "                print(\"当前处理文件是：\" + file_path)\n",
    "                # 读取.npz文件\n",
    "                print(\"Current parameters:\")\n",
    "                print(f\"CONTEXT = {CONTEXT},  LAMBDA_RIDGE = {LAMBDA_RIDGE}\")\n",
    "                print(\n",
    "                    f\"LEARNING_RATE = {LEARNING_RATE}, MAX_ITERATIONS = {MAX_ITERATIONS}, CHECK_EVERY = {CHECK_EVERY}\")\n",
    "                data = np.load(file_path)\n",
    "                # 从文件中提取'X'和'GC'数据\n",
    "                X_np = data['X']\n",
    "                GC = data['GC']\n",
    "\n",
    "                # 将X_np转换为torch tensor\n",
    "                X = torch.tensor(X_np[np.newaxis], dtype=torch.float32, device=device)\n",
    "\n",
    "                clstm = cLSTM(X.shape[-1], hidden=100).cuda(device=device)\n",
    "                # Train with ISTA\n",
    "                # 对每个lambda值进行实验\n",
    "                for LAMBDA in LAMBDA_RANGE:\n",
    "                    print(f\"当前 LAMBDA = {LAMBDA:.4f}\")\n",
    "                    train_loss_list = train_model_ista(\n",
    "                        clstm, X,\n",
    "                        context=CONTEXT,\n",
    "                        lam=LAMBDA,\n",
    "                        lam_ridge=LAMBDA_RIDGE,\n",
    "                        lr=LEARNING_RATE,\n",
    "                        max_iter=MAX_ITERATIONS,\n",
    "                        check_every=CHECK_EVERY\n",
    "                    )\n",
    "\n",
    "                    # Check learned Granger causality\n",
    "                    GC_est = clstm.GC().cpu().data.numpy()\n",
    "\n",
    "                    # 将数组展平，计算fpr和tpr\n",
    "                    GC_flat = GC.flatten()\n",
    "                    GC_est_flat = GC_est.flatten()\n",
    "\n",
    "                    # 计算混淆矩阵\n",
    "                    tn, fp, fn, tp = confusion_matrix(GC_flat, GC_est_flat).ravel()\n",
    "\n",
    "                    # 计算 FPR 和 TPR\n",
    "                    fpr = fp / (fp + tn)\n",
    "                    tpr = tp / (tp + fn)\n",
    "\n",
    "                    print(f\"ROC Curve Point: FPR = {fpr:.4f}, TPR = {tpr:.4f}\")\n",
    "\n",
    "                    print('True variable usage = %.2f%%' % (100 * np.mean(GC)))\n",
    "                    print('Estimated variable usage = %.2f%%' % (100 * np.mean(GC_est)))\n",
    "                    print('Accuracy = %.2f%%' % (100 * np.mean(GC == GC_est)))\n",
    "                    # logger.info('True variable usage = %.2f%%' % (100 * np.mean(GC)))\n",
    "                    # logger.info('Estimated variable usage = %.2f%%' % (100 * np.mean(GC_est)))\n",
    "                    # logger.info('Accuracy = %.2f%%' % (100 * np.mean(GC == GC_est)))\n",
    "\n",
    "                    # Make figures\n",
    "                    fig, axarr = plt.subplots(1, 2, figsize=(10, 5))\n",
    "                    axarr[0].imshow(GC, cmap='Blues')\n",
    "                    axarr[0].set_title('GC actual')\n",
    "                    axarr[0].set_ylabel('Affected series')\n",
    "                    axarr[0].set_xlabel('Causal series')\n",
    "                    axarr[0].set_xticks([])\n",
    "                    axarr[0].set_yticks([])\n",
    "\n",
    "                    axarr[1].imshow(GC_est, cmap='Blues', vmin=0, vmax=1, extent=(0, len(GC_est), len(GC_est), 0))\n",
    "                    axarr[1].set_ylabel('Affected series')\n",
    "                    axarr[1].set_xlabel('Causal series')\n",
    "                    axarr[1].set_xticks([])\n",
    "                    axarr[1].set_yticks([])\n",
    "\n",
    "                    # Mark disagreements\n",
    "                    for i in range(len(GC_est)):\n",
    "                        for j in range(len(GC_est)):\n",
    "                            if GC[i, j] != GC_est[i, j]:\n",
    "                                rect = plt.Rectangle((j, i - 0.05), 1, 1, facecolor='none', edgecolor='red',\n",
    "                                                     linewidth=1)\n",
    "                                axarr[1].add_patch(rect)\n",
    "\n",
    "                    plt.show()\n",
    "# sys.stdout = sys.stdout.terminal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "dadfce5c11ba2debf270ee6e74ab56ef64244eeb7b74fdb0e454e37cbe06d6e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
