{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cLSTM Lorenz-96 Demo\n",
    "- In this notebook, we train a cLSTM model on data simulated from a Lorenz-96 system"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()\n",
    "# 显示当前jupyter启动在哪\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T16:48:29.959324Z",
     "start_time": "2024-11-21T16:48:29.947899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/autodl-tmp/Neural-GC-master'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T16:48:31.320818Z",
     "start_time": "2024-11-21T16:48:29.961055Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from models.clstm import cLSTM, train_model_ista"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T16:48:31.423585Z",
     "start_time": "2024-11-21T16:48:31.322696Z"
    }
   },
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# import sys\n",
    "# import os\n",
    "# from datetime import datetime\n",
    "# import logging\n",
    "# \n",
    "# # 获取当前时间作为文件名的一部分\n",
    "# current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S_%f\")\n",
    "# log_filename = f\"log_{current_time}.txt\"\n",
    "# \n",
    "# # 确保日志文件夹存在\n",
    "# log_dir = \"logs\"\n",
    "# if not os.path.exists(log_dir):\n",
    "#     os.makedirs(log_dir)\n",
    "# \n",
    "# log_path = os.path.join(log_dir, log_filename)\n",
    "# \n",
    "# \n",
    "# # 创建一个同时写入控制台和文件的类\n",
    "# class Logger(object):\n",
    "#     def __init__(self, filename=\"Default.log\"):\n",
    "#         self.terminal = sys.stdout\n",
    "#         self.log = open(filename, \"w\")\n",
    "# \n",
    "#     def write(self, message):\n",
    "#         self.terminal.write(message)\n",
    "#         self.log.write(message)\n",
    "#         self.flush()  # 确保实时写入\n",
    "# \n",
    "#     def flush(self):\n",
    "#         self.terminal.flush()\n",
    "#         self.log.flush()\n",
    "# \n",
    "#     def __del__(self):\n",
    "#         self.log.close()\n",
    "# \n",
    "# \n",
    "# # 重定向 sys.stdout 到 Logger 实例\n",
    "# sys.stdout = Logger(log_path)\n",
    "# \n",
    "# # 示例打印\n",
    "# print(\"This is a test log message.\")\n",
    "# sys.stdout = sys.__stdout__  # 恢复到原始的 sys.stdout\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-21T16:48:31.429517Z",
     "start_time": "2024-11-21T16:48:31.425721Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-21T16:48:31.430953Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 指定根文件夹路径\n",
    "root_path = 'datasets/lorenz/F20'\n",
    "# Define parameters at the beginning of the file\n",
    "CONTEXT = 10\n",
    "# LAMBDA = 5.0\n",
    "LAMBDA_RIDGE = 1e-2\n",
    "LEARNING_RATE = 1e-3\n",
    "MAX_ITERATIONS = 20000\n",
    "CHECK_EVERY = 50\n",
    "# 定义固定的 lambda 值\n",
    "LAMBDA_RANGE = [0.1, 0.3, 0.7, 1.0, 2.0, 3.5, 5.0, 10.0, 15.0, 20.0]\n",
    "\n",
    "# 遍历文件夹结构\n",
    "for folder1 in os.listdir(root_path):\n",
    "    folder1_path = root_path + '/' + folder1\n",
    "    for file in os.listdir(folder1_path):\n",
    "        if file.endswith('.npz'):\n",
    "            file_path = folder1_path + '/' + file\n",
    "            print(\"当前处理文件是：\" + file_path)\n",
    "            # 读取.npz文件\n",
    "            print(\"Current parameters:\")\n",
    "            print(f\"CONTEXT = {CONTEXT},  LAMBDA_RIDGE = {LAMBDA_RIDGE}\")\n",
    "            print(\n",
    "                f\"LEARNING_RATE = {LEARNING_RATE}, MAX_ITERATIONS = {MAX_ITERATIONS}, CHECK_EVERY = {CHECK_EVERY}\")\n",
    "            data = np.load(file_path)\n",
    "            # 从文件中提取'X'和'GC'数据\n",
    "            X_np = data['X']\n",
    "            GC = data['GC']\n",
    "\n",
    "            # 将X_np转换为torch tensor\n",
    "            X = torch.tensor(X_np[np.newaxis], dtype=torch.float32, device=device)\n",
    "\n",
    "            clstm = cLSTM(X.shape[-1], hidden=100).cuda(device=device)\n",
    "            # Train with ISTA\n",
    "            # 对每个lambda值进行实验\n",
    "            for LAMBDA in LAMBDA_RANGE:\n",
    "                print(f\"当前 LAMBDA = {LAMBDA:.4f}\")\n",
    "                train_loss_list = train_model_ista(\n",
    "                    clstm, X,\n",
    "                    context=CONTEXT,\n",
    "                    lam=LAMBDA,\n",
    "                    lam_ridge=LAMBDA_RIDGE,\n",
    "                    lr=LEARNING_RATE,\n",
    "                    max_iter=MAX_ITERATIONS,\n",
    "                    check_every=CHECK_EVERY\n",
    "                )\n",
    "\n",
    "                # Check learned Granger causality\n",
    "                GC_est = clstm.GC().cpu().data.numpy()\n",
    "\n",
    "                # 将数组展平，计算fpr和tpr\n",
    "                GC_flat = GC.flatten()\n",
    "                GC_est_flat = GC_est.flatten()\n",
    "\n",
    "                # 计算混淆矩阵\n",
    "                tn, fp, fn, tp = confusion_matrix(GC_flat, GC_est_flat).ravel()\n",
    "\n",
    "                # 计算 FPR 和 TPR\n",
    "                fpr = fp / (fp + tn)\n",
    "                tpr = tp / (tp + fn)\n",
    "\n",
    "                print(f\"ROC Curve Point: FPR = {fpr:.4f}, TPR = {tpr:.4f}\")\n",
    "\n",
    "                print('True variable usage = %.2f%%' % (100 * np.mean(GC)))\n",
    "                print('Estimated variable usage = %.2f%%' % (100 * np.mean(GC_est)))\n",
    "                print('Accuracy = %.2f%%' % (100 * np.mean(GC == GC_est)))\n",
    "                # logger.info('True variable usage = %.2f%%' % (100 * np.mean(GC)))\n",
    "                # logger.info('Estimated variable usage = %.2f%%' % (100 * np.mean(GC_est)))\n",
    "                # logger.info('Accuracy = %.2f%%' % (100 * np.mean(GC == GC_est)))\n",
    "\n",
    "                # Make figures\n",
    "                fig, axarr = plt.subplots(1, 2, figsize=(10, 5))\n",
    "                axarr[0].imshow(GC, cmap='Blues')\n",
    "                axarr[0].set_title('GC actual')\n",
    "                axarr[0].set_ylabel('Affected series')\n",
    "                axarr[0].set_xlabel('Causal series')\n",
    "                axarr[0].set_xticks([])\n",
    "                axarr[0].set_yticks([])\n",
    "\n",
    "                axarr[1].imshow(GC_est, cmap='Blues', vmin=0, vmax=1, extent=(0, len(GC_est), len(GC_est), 0))\n",
    "                axarr[1].set_ylabel('Affected series')\n",
    "                axarr[1].set_xlabel('Causal series')\n",
    "                axarr[1].set_xticks([])\n",
    "                axarr[1].set_yticks([])\n",
    "\n",
    "                # Mark disagreements\n",
    "                for i in range(len(GC_est)):\n",
    "                    for j in range(len(GC_est)):\n",
    "                        if GC[i, j] != GC_est[i, j]:\n",
    "                            rect = plt.Rectangle((j, i - 0.05), 1, 1, facecolor='none', edgecolor='red',\n",
    "                                                 linewidth=1)\n",
    "                            axarr[1].add_patch(rect)\n",
    "\n",
    "                plt.show()\n",
    "# sys.stdout = sys.stdout.terminal"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前处理文件是：datasets/lorenz/F10/time1000/lorenz-169-F10-1000.npz\n",
      "Current parameters:\n",
      "CONTEXT = 10,  LAMBDA_RIDGE = 0.01\n",
      "LEARNING_RATE = 0.001, MAX_ITERATIONS = 20000, CHECK_EVERY = 50\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "dadfce5c11ba2debf270ee6e74ab56ef64244eeb7b74fdb0e454e37cbe06d6e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
